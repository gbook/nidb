---
description: JSON array
---

# pipelines

Pipelines are the methods used to analyze data after it has been collected. In other words, the experiment provides the methods to collect the data and the pipelines provide the methods to analyze the data once it has been collected.

Basic pipeline information is stored in the main `squirrel.json` file, and complete pipeline information is stored in the pipeline subdirectory in the `pipeline.json` file.

<figure><img src="https://mermaid.ink/img/pako:eNqVVFFvmzAQ_iuRq0hEgohENCWu1KfuZZo2aX2beLnhI_EKGNlGC4vy32cbTALtQ-sH-zvu--7OdzJnkguGhJKDhOa4-PYzqxdmSSF0FD01kL_CAYPhXD1evcHXlx_fHVoZIgMNgd1uKTYAb7DkNapgRDMGnhqUvMJaq-AGz1g2NOO5djkii7ioQXarnuW-Rk-q_f0HcxPIAx9l8B-kaBuooewUV4GzIm96qpfacLpl3JQ-nO8wKgTVSkPx4B0Ok-1BBW4fvX1Am8Lc12Zwx1v3WOu8yuWyl0RrOyQJlSp4aedkoSe9pdo-WKKazGq5vGm8pV3Nnny1F-7DyuvGobo6BqPXeGum8BexAo97gbcmgvEKuitxMZZvOSW9K4oiNN2S4hUjBuoIUkJHt1PRJMtnhLMufEY6acVHhDP5ONGPaKcpr-nwPo7DXkTvkiQZcPSXM32kSXMiIalQVsCZef9nGywj-ogVZoQayLCAttQZyeqLobaNaT9-YVwLSWgBpcKQQKvFS1fnhGrZoic9czC_k2pkmTf3S4iJTeiZnAiNQ9IRuo13612aPKS7dPOwTfdJegnJP6eI1_t-pff7zWa3TdPLf80tlNs?type=png" alt=""><figcaption></figcaption></figure>

### JSON Variables

\*required

<table data-header-hidden><thead><tr><th width="288" align="right"></th><th width="155.00000000000003"></th><th></th></tr></thead><tbody><tr><td align="right"><em><strong>Variable</strong></em></td><td><strong>Type</strong></td><td><strong>Description</strong></td></tr><tr><td align="right"><code>ClusterType</code></td><td>string</td><td>Compute cluster engine (sge or slurm).</td></tr><tr><td align="right"><code>ClusterUser</code></td><td>string</td><td>Submit username.</td></tr><tr><td align="right"><code>ClusterQueue</code></td><td>string</td><td>Queue to submit jobs.</td></tr><tr><td align="right"><code>ClusterSubmitHost</code></td><td>string</td><td>Hostname to submit jobs.</td></tr><tr><td align="right"><code>CompleteFiles</code></td><td>JSON array</td><td>JSON array of complete files, with relative paths to <code>analysisroot</code>.</td></tr><tr><td align="right"><code>CreateDate</code></td><td>datetime</td><td>Date the pipeline was created.</td></tr><tr><td align="right"><code>DataCopyMethod</code></td><td>string</td><td>How the data is copied to the analysis directory: <code>cp</code>, <code>softlink</code>, <code>hardlink</code>.</td></tr><tr><td align="right"><code>DependencyDirectory</code></td><td>string</td><td> </td></tr><tr><td align="right"><code>DependencyLevel</code></td><td>string</td><td> </td></tr><tr><td align="right"><code>DependencyLinkType</code></td><td>string</td><td> </td></tr><tr><td align="right"><code>Description</code></td><td>string</td><td>Longer pipeline description.</td></tr><tr><td align="right"><code>DirectoryStructure</code></td><td>string</td><td> </td></tr><tr><td align="right"><code>Directory</code></td><td>string</td><td>Directory where the analyses for this pipeline will be stored. Leave blank to use the default location.</td></tr><tr><td align="right"><code>Group</code></td><td>string</td><td>ID or name of a group on which this pipeline will run</td></tr><tr><td align="right"><code>GroupType</code></td><td>string</td><td>Either subject or study</td></tr><tr><td align="right"><code>Level</code></td><td>number</td><td>subject-level analysis (1) or group-level analysis (2). <mark style="color:red;">REQUIRED</mark></td></tr><tr><td align="right"><code>MaxWallTime</code></td><td>number</td><td>Maximum allowed clock (wall) time in minutes for the analysis to run</td></tr><tr><td align="right"><code>PipelineName</code></td><td>string</td><td>Pipeline name. <mark style="color:red;">REQUIRED</mark></td></tr><tr><td align="right"><code>Notes</code></td><td>string</td><td>Extended notes about the pipeline</td></tr><tr><td align="right"><code>NumberConcurrentAnalyses</code></td><td>number</td><td>Number of analyses allowed to run at the same time. This number if managed by NiDB and is different than grid engine queue size.</td></tr><tr><td align="right"><code>ParentPipelines</code></td><td>string</td><td>Comma separated list of parent pipelines.</td></tr><tr><td align="right"><code>ResultScript</code></td><td>string</td><td>Executable script to be run at completion of the analysis to find and insert results back into NiDB.</td></tr><tr><td align="right"><code>SubmitDelay</code></td><td>number</td><td>Delay in hours, after the study datetime, to submit to the cluster. Allows time to upload behavioral data. </td></tr><tr><td align="right"><code>TempDirectory</code></td><td>string</td><td>The path to a temporary directory if it is used, on a compute node. </td></tr><tr><td align="right"><code>UseProfile</code></td><td>bool</td><td>true if using the profile option, false otherwise.</td></tr><tr><td align="right"><code>UseTempDirectory</code></td><td>bool</td><td>true if using a temporary directory, false otherwise.</td></tr><tr><td align="right"><code>Version</code></td><td>number</td><td>Version of the pipeline.</td></tr><tr><td align="right"><code>PrimaryScript</code></td><td>string</td><td>See details of <a href="pipeline-scripts.md">pipeline scripts</a></td></tr><tr><td align="right"><code>SecondaryScript</code></td><td>string</td><td>See details of <a href="pipeline-scripts.md">pipeline scripts</a>.</td></tr><tr><td align="right"><code>VirtualPath</code></td><td>string</td><td>Path of this pipeline within the squirrel package.</td></tr><tr><td align="right"><code>DataStepCount</code></td><td>number</td><td>Number of data steps.</td></tr><tr><td align="right"><a href="data-steps.md">data-steps</a></td><td>JSON array</td><td>See <a href="data-steps.md">data specifications</a></td></tr></tbody></table>

### Directory structure

Files associated with this section are stored in the following directory. `PipelineName` is the unique name of the pipeline.

> `/pipelines/<PipelineName>`
